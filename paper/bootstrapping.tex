In this section, we present our algorithm for bootstrapping new examples 
from expert demonstrations. At its core, the idea is simple: if we get
examples of new states that are able to successfully transfer a trajectory to,
we get a new example of a successful manipulation. We can use these examples
to transfer trajectories better in new settings.

\subsection{Modelling Transfer Sets}
Formally, we assume access to an environment and a reward signal. In our work, this
environment is a simulated although in the approach can apply to real settings. 
Our reward signal is a 1-0 response which tells us if a manipulation succeeds. For 
tasks involving several steps, we associate success with a manipulation if a success
signal is received before a fixed time horizon is reached.

To ease discussion, we introduce the concept of a \emph{transfer set}. Given a method for
transfering a demonstration trajectory to a new state, the associated transfer set is
the set of states such that the transferred trajectory will successfully execute the
demonstrated manipulation. With this terminology, we can consider the nearest-neighbor
selection method from Schulman et al.~\cite{Schulmanetal_ISRR2013} as approximating the
transfer set for a particular demonstration with a hyper-sphere defined with respect
to the registration cost.

\begin{algorithm}
 \KwData{Env, O, T}
 \KwResult{S_T}
 \For{t \in T}{
        S_T[t] = s_t\;
        }
        
 \While{not at end of this document}{
  read current\;
  \eIf{understand}{
   go to next section\;
   current section becomes this one\;
   }{
   go back to the beginning of current section\;
  }
 }
 \caption{Building Transfer Set Models}
 \label{alg:trans-set}
\end{algorithm}

A first step to improving the selction step is to build a richer
model of the transfer set associated with a trajectory. Given a set of
states that a trajectory, $t$,  has been successfully transferred to, $S_T$, we can
model a transfer set with a collection of hyper-spheres around those states.
Then, when it comes time to select a trajectory to generalize, we pick according to
the following rule:
\begin{equation}
\underset{t}{\argmin} \ \ \underset{s\in S_t}{\min} \ \ {\text registration\_cost}(s).
\end{equation}
Alg.~\ref{alg:trans-set} illustrates a greedy algorithm for building up the sets $S_t$ given
access to a simulation environment and a reward signal. 

\subsection{Bootstrapping New Examples}
Building a better model of the transfer set for a trajectory provides a way
to better select trajectories. However, it discards a reasonable amount of
data. During execution, have access to the transferred trajectories in addition
to the states they were transferred to. In some sense, these are new examples of 
successful manipulations in their own right. Instead of simply storing
the states we successfully transfer to, we can add those examples to our trajectory 
library and consider transfering the derived trajectories to new scenes. 
Alg.~\ref{alg:bootstrap} shows a greedy method for building a bootstrapped trajectory
library from experience.

\begin{algorithm}
 \KwData{Env, O, T}
 \KwResult{S_T}
 \For{t \in T}{
        S_T[t] = s_t\;
        }
        
 \While{not at end of this document}{
  read current\;
  \eIf{understand}{
   go to next section\;
   current section becomes this one\;
   }{
   go back to the beginning of current section\;
  }
 }
 \caption{Bootstrapping a Trajectory Library}
 \label{alg:bootstrap}
\end{algorithm}

One possible objection to this method is as follows: given that these derived examples
simply deformations of an original, why would we expect this to be better than simply
transferring the original? The answer to this question is based in different
aspects of the TPS approach to trajectory transfer.

The first is that, in addition to finding a transfer function that minimizes curvature,
we are also finding correspondences between points in the different scenes. Finding 
correspondences is a difficult and well-studied problem in computer vision and the best
approaches are subject to local optima. The TPS-RPM algorithm is no exception. 

We could appeal to local features to improve this difficulty, but finding feaure descriptors 
that capture important aspects of general manipulation problems is a difficult task. The
states we add to our trajectory library are examples of states and correspondences that 
successfully transferred a demonstration trajectory. By transferring directly from those
states, as opposed to the original demonstration state, we are providing a better 
initialization to the TPS-RPM algorithm and we should be able to find better correspondences
between points.

The second reason we would expect this to be successful is that in transferring derived
states and trajectories, the we enable the use of a broader class of functions for 
transferring trajectories. In transferring a trajectory, $t$, from state $s_1$ through
state $s_2$ to $s_3$, we compute a thin plate spline from $s_1$ to $s_2$ 
($f_{1\rightarrow 2}$) then from $s_2$ to $s_3$ ($f_{2\rightarrow 3}$). The trajectory we
execute is then $f_{1\rightarrow 2}(f_{2\rightarrow 3}(t)) \ne f_{1\rightarrow 3}(t)$. 
Instead of using a thin plate spline, we are using a form of iterated thin plate spline.

The intuition behind this is that a thin plate spline represents an encoding of a preference
for non-rigid functions to transfer a state. For a general approach, this is a good
prefernce to have. However, for a particular manipulation task, not all deformations
will have the same effect on transfer success. 

As an example, consider a robot transferring
trajectories for openning a drawer. In transferring the first portion of a demonstration,
almost any deformation is ok: all that needs to happen is that the robot grabs the drawer handle.
However, for the second part---actually openning the drawer---almost any non-rigid deformation
will result in a failed transfer.

In fitting a thin plate spline to derived trajectories, we gain the ability 
to learn these transfer properties for the manipulation we are exploring.
The non-rigid deformations that resulted in successful transfers are no longer
penalized in fitting the thin plate spline. For our drawer example, after enough
examples of successful transfers this technique would effectively learn to allow
certain types of deformations (e.g. those that allow us to grab the drawer) but still
maintain the ability to penalize for others (e.g. defomations that don't allow the robot to
open the drawer).


